import numpy as np
import pickle
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# Load test data
X_test = np.load("data/preprocessed/X_vgg16.npy")  # Change to any feature set you want to evaluate
y_test = np.load("data/preprocessed/y.npy")

# Load models
models = {
    "Logistic Regression": pickle.load(open("models/logistic_regression_vgg16.pkl", "rb")),
    "KNN": pickle.load(open("models/knn_vgg16.pkl", "rb")),
    "Decision Tree": pickle.load(open("models/decision_tree_vgg16.pkl", "rb")),
    "Random Forest": pickle.load(open("models/random_forest_vgg16.pkl", "rb"))
}

# Evaluate models
results = {}
for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='weighted')
    rec = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    results[name] = {"accuracy": acc, "precision": prec, "recall": rec, "f1-score": f1}

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix - {name}")
    plt.show()

# Save results
np.save("reports/classifier_results.npy", results)
print("Evaluation completed and results saved.")
